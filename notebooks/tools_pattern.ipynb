{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1115efeb",
   "metadata": {},
   "source": [
    "### A Simple Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55a0b538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0574e5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location: str, unit: str):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    if location == \"Hanoi\":\n",
    "        return json.dumps({\"Temperature\": 20, \"unit\": unit})\n",
    "    else:\n",
    "        return json.dumps({\"Temperature\": 50, \"unit\": unit})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21438d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Temperature\": 20, \"unit\": \"celsius\"}'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather(\"Hanoi\", unit=\"celsius\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7706aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Remember to load the environment variables. You should have the Groq API Key in there :)\n",
    "load_dotenv()\n",
    "\n",
    "MODEL = \"llama-3.3-70b-versatile\"\n",
    "GROQ_CLIENT = Groq()\n",
    "\n",
    "# Define the System Prompt as a constant\n",
    "TOOL_SYSTEM_PROMPT = \"\"\"\n",
    "Bạn là một mô hình AI gọi hàm. Bạn được cung cấp các chữ ký hàm trong thẻ XML <tools></tools>.\n",
    "Bạn có thể gọi một hoặc nhiều hàm để hỗ trợ truy vấn của người dùng. Đừng đưa ra giả định về giá trị cần truyền vào hàm.\n",
    "Hãy đặc biệt chú ý đến thuộc tính 'types'. Bạn nên sử dụng các kiểu dữ liệu này giống như trong một từ điển Python.\n",
    "Đối với mỗi lần gọi hàm, hãy trả về một đối tượng JSON với tên hàm và các đối số trong thẻ XML <tool_call></tool_call> như sau:\n",
    "<tool_call>\n",
    "\n",
    "{\"name\": <tên hàm>,\"arguments\": <từ điển đối số>}\n",
    "\n",
    "</tool_call>\n",
    "\n",
    "Đây là các công cụ có sẵn:\n",
    "\n",
    "<tools> {\n",
    "    \"name\": \"get_current_weather\",\n",
    "    \"description\": \"Lấy thời tiết hiện tại tại một vị trí nhất định location (str): Thành phố và tiểu bang, ví dụ: Hanoi, Danang unit (str): Đơn vị. Nó có thể nhận hai giá trị; 'độ C', 'độ F',\n",
    "    \"parameters\": {\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"str\"\n",
    "            },\n",
    "            \"unit\": {\n",
    "                \"type\": \"str\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "</tools>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "371b88e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tool_call>\n",
      "{\n",
      "    \"name\": \"get_current_weather\",\n",
      "    \"arguments\": {\n",
      "        \"location\": \"Hanoi\",\n",
      "        \"unit\": \"độ C\"\n",
      "    }\n",
      "}\n",
      "</tool_call>\n"
     ]
    }
   ],
   "source": [
    "tool_chat_history = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": TOOL_SYSTEM_PROMPT\n",
    "    }\n",
    "]\n",
    "agent_chat_history = []\n",
    "\n",
    "user_msg = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"What's the current temperature in Hanoi, in Celsius?\"\n",
    "}\n",
    "\n",
    "tool_chat_history.append(user_msg)\n",
    "agent_chat_history.append(user_msg)\n",
    "\n",
    "output = GROQ_CLIENT.chat.completions.create(\n",
    "    messages=tool_chat_history,\n",
    "    model=MODEL\n",
    ").choices[0].message.content\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60f8ee11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ngocson/NSN/Project\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8bbe9539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from src.agentic_patterns.tool_pattern.tool import *\n",
    "from src.agentic_patterns.tool_pattern.tool_agent import ToolAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4f29fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from src.agentic_patterns.tool_pattern.tool import tool\n",
    "from src.agentic_patterns.tool_pattern.tool_agent import ToolAgent\n",
    "\n",
    "def fetch_top_hacker_news_stories(top_n: int):\n",
    "    \"\"\"\n",
    "    Fetch the top stories from Hacker News.\n",
    "\n",
    "    This function retrieves the top `top_n` stories from Hacker News using the Hacker News API. \n",
    "    Each story contains the title, URL, score, author, and time of submission. The data is fetched \n",
    "    from the official Firebase Hacker News API, which returns story details in JSON format.\n",
    "\n",
    "    Args:\n",
    "        top_n (int): The number of top stories to retrieve.\n",
    "    \"\"\"\n",
    "    top_stories_url = 'https://hacker-news.firebaseio.com/v0/topstories.json'\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(top_stories_url)\n",
    "        response.raise_for_status()  # Check for HTTP errors\n",
    "        \n",
    "        # Get the top story IDs\n",
    "        top_story_ids = response.json()[:top_n]\n",
    "        \n",
    "        top_stories = []\n",
    "        \n",
    "        # For each story ID, fetch the story details\n",
    "        for story_id in top_story_ids:\n",
    "            story_url = f'https://hacker-news.firebaseio.com/v0/item/{story_id}.json'\n",
    "            story_response = requests.get(story_url)\n",
    "            story_response.raise_for_status()  # Check for HTTP errors\n",
    "            story_data = story_response.json()\n",
    "            \n",
    "            # Append the story title and URL (or other relevant info) to the list\n",
    "            top_stories.append({\n",
    "                'title': story_data.get('title', 'No title'),\n",
    "                'url': story_data.get('url', 'No URL available'),\n",
    "            })\n",
    "        \n",
    "        return json.dumps(top_stories)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d0b2064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Beginning January 2026, all ACM publications will be made open access',\n",
       "  'url': 'https://dl.acm.org/openaccess'},\n",
       " {'title': '1.5 TB of VRAM on Mac Studio – RDMA over Thunderbolt 5',\n",
       "  'url': 'https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5'},\n",
       " {'title': 'History LLMs: Models trained exclusively on pre-1913 texts',\n",
       "  'url': 'https://github.com/DGoettlich/history-llms'},\n",
       " {'title': 'We pwned X, Vercel, Cursor, and Discord through a supply-chain attack',\n",
       "  'url': 'https://gist.github.com/hackermondev/5e2cdc32849405fff6b46957747a2d28'},\n",
       " {'title': 'Texas is suing all of the big TV makers for spying on what you watch',\n",
       "  'url': 'https://www.theverge.com/news/845400/texas-tv-makers-lawsuit-samsung-sony-lg-hisense-tcl-spying'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(fetch_top_hacker_news_stories(top_n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bcdea4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hn_tool = tool(fetch_top_hacker_news_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72651deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_agent = ToolAgent(tools=[hn_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97149fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tool_agent.run(user_msg=\"1+ 5 bằng mấy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f369b587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 + 5 = 6\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
